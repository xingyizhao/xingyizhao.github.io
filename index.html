<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Xingyi Zhao</title>
  <meta name="description" content="Xingyi Zhao — PhD student in NLP & AI security." />
  <!-- Cache-bust so CSS updates always show -->
  <link rel="stylesheet" href="style.css?v=1" />
</head>
<body>
  <div class="container">

    <div class="nav">
      <a href="#about">About</a>
      <a href="#research">Research</a>
      <a href="#publications">Publications</a>
      <a href="cv.html">CV</a>
      <a href="#contact">Contact</a>
    </div>

    <!-- HERO -->
    <div class="hero" id="about">
      <!-- IMPORTANT: use hero-left so your CSS applies -->
      <div class="hero-left">
        <h1>Xingyi Zhao</h1>
        <h2>PhD Student, Utah State University • NLP & AI Security</h2>

        <p>
          I am a last year Ph.D student in Computer Science at Utah State University,
          advised by <a href="https://yuan.shuhan.org/" target="_blank" rel="noopener">Dr. Shuhan Yuan</a>.
          I received both my B.Eng. and M.Eng. from the School of Artificial Intelligence and Automation,
          Huazhong University of Science and Technology (HUST). My research focuses on LLMs security and
          safe post-training, with interests in faithful reasoning, red-teaming, and alignment-oriented
          training methods (e.g., SFT and RLHF). My recent works mainly focus on exploring how malicious behaviors emerge and persist in large
          language models, and I develop practical methods for malicious alignment analysis, harmful
          information unlearning, and safety post-training while preserving model utility.
        </p>

        <p class="small">
          <a href="https://scholar.google.com/citations?user=yVq7_1sAAAAJ&hl=en" target="_blank" rel="noopener">Google Scholar</a> ·
          <a href="https://github.com/xingyizhao" target="_blank" rel="noopener">GitHub</a> ·
          <a href="https://www.linkedin.com/in/xingyi-zhao-407375239/" target="_blank" rel="noopener">LinkedIn</a>
        </p>
      </div>

      <div>
        <!-- Tip: avoid spaces in filenames; rename to xingyi-zhao.jpg if possible -->
        <img class="profile-photo" src="xingyi zhao.jpg" alt="Xingyi Zhao" />
      </div>
    </div>

    <div class="section" id="Selected Publications">
    <div class="section-title">Selected Publications</div>

    <div class="pub pub-with-thumb">
      <div class="pub-left">
        <span class="tag tag-purple">ICLR</span>
        <img class="pub-thumb" src="RGA.png" alt="Paper thumbnail: Don't Shift the Trigger: Robust Gradient Ascent for Backdoor Unlearning" />
      </div>

      <div class="pub-right">
        <div class="pub-title">Don't Shift the Trigger: Robust Gradient Ascent for Backdoor Unlearning</div>
    
        <div class="pub-authors">
          <strong>Xingyi Zhao</strong>, Tian Xie, Xiaojun Qi, Depeng Xu, Shuhan Yuan
        </div>
    
        <div class="pub-venue">
          In Proceedings of the 14th International Conference on Learning Representation (ICLR), 2026
        </div>
    
        <div class="pub-links">
          <a class="btn" href="https://openreview.net/forum?id=voqtsqYS6j" target="_blank" rel="noopener">PDF</a>
          <a class="btn" href="https://github.com/xingyizhao/RGA" target="_blank" rel="noopener">CODE</a>
        </div>
      </div>
    </div>

    <div class="pub pub-with-thumb">
    <div class="pub-left">
      <span class="tag tag-purple">ICML</span>
      <img class="pub-thumb" src="PURE.png" alt="Paper thumbnail: Defense against Backdoor Attack on Pre-trained Language Models via Head Pruning and Attention Normalization" />
    </div>

    <div class="pub-right">
      <div class="pub-title">Defense against Backdoor Attack on Pre-trained Language Models via Head Pruning and Attention Normalization</div>
  
      <div class="pub-authors">
        <strong>Xingyi Zhao</strong>, Depeng Xu, Shuhan Yuan
      </div>
  
      <div class="pub-venue">
        In Proceedings of the 41st International Conference on Machine Learning (ICML), 2024
      </div>
  
      <div class="pub-links">
        <a class="btn" href="https://proceedings.mlr.press/v235/zhao24r.html" target="_blank" rel="noopener">PDF</a>
        <a class="btn" href="https://github.com/xingyizhao/PURE" target="_blank" rel="noopener">CODE</a>
      </div>
    </div>
  </div>
  </div>

  </div>

  <script>
    document.getElementById("y").textContent = new Date().getFullYear();
  </script>
</body>
</html>
